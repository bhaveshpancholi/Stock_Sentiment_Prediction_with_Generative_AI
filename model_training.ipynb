{"cells":[{"cell_type":"markdown","metadata":{},"source":["### Installing dependencies"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":54278,"status":"ok","timestamp":1698221935680,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"hHRVOTimafH7","outputId":"bcb23f62-f4f0-43be-b56f-9bdb4a3cf8cd"},"outputs":[],"source":["!pip install xlsxwriter\n","!pip install -q bitsandbytes datasets accelerate loralib\n","!pip install -q git+https://github.com/huggingface/transformers.git@main git+https://github.com/huggingface/peft.git\n","!pip install GPUtil\n","!pip install rouge_score sentence_transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3512,"status":"ok","timestamp":1698221939182,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"aNxhq2kY5ly0","outputId":"26fbe9c4-3958-46c8-d25f-3c749c691a78"},"outputs":[],"source":["# from google.colab import drive\n","# drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":22343,"status":"ok","timestamp":1698221973870,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"ukob7GrMroCM"},"outputs":[],"source":["import pandas as pd\n","import os\n","import re\n","import numpy as np\n","import copy\n","from tqdm import tqdm\n","from typing import Dict, Optional, Sequence, Tuple\n","import torch\n","from torch.utils.data import DataLoader\n","from transformers import (\n","  PreTrainedTokenizer,\n","  AutoModelForCausalLM,\n","  AutoTokenizer,\n","  BitsAndBytesConfig,\n","  AutoConfig,\n","  default_data_collator,\n","  DataCollatorForLanguageModeling,\n","  DataCollatorWithPadding,\n","  get_linear_schedule_with_warmup,\n","  TrainingArguments,\n","  Trainer,\n","  TrainerCallback\n",")\n","from peft import prepare_model_for_int8_training, prepare_model_for_kbit_training, get_peft_config, get_peft_model, PromptTuningInit, PromptTuningConfig, PrefixTuningConfig, LoraConfig, TaskType, PeftType, PeftConfig, PeftModel\n","from datasets import load_dataset, DatasetDict, Dataset\n","from GPUtil import showUtilization as gpu_usage\n","\n","from nltk.translate.bleu_score import sentence_bleu\n","from rouge_score import rouge_scorer\n","from sentence_transformers import SentenceTransformer, util\n","\n","import warnings\n","warnings.filterwarnings('ignore')"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":35,"status":"ok","timestamp":1698221973871,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"2kTsd1yJGmng"},"outputs":[],"source":["num_epochs = 2\n","batch_size = 2\n","lr = 0.001\n","rank = 8\n","max_length = 2000\n","data_collator = None\n","\n","MODEL_PATH = \"/content/drive/MyDrive/Stocks/raw_models/Llama-2-7b-chat-hf\"\n","# MODEL_PATH = \"/content/drive/MyDrive/Stocks/raw_models/dolly-v2-3b\"\n","# MODEL_PATH = \"gpt2-large\"\n","\n","LOCAL_OUTPUT_DIR = \"/content/drive/MyDrive/Stocks/finetune_models/Llama-2-7b-chat-hf/\"\n","# LOCAL_OUTPUT_DIR = \"/content/drive/MyDrive/Stocks/finetune_models/dolly-v2-3b/\"\n","# LOCAL_OUTPUT_DIR = \"/content/drive/MyDrive/Stocks/finetune_models/gpt2-large/\"\n","\n","LOCAL_OUTPUT_DIR = LOCAL_OUTPUT_DIR + f\"ep{num_epochs}_bs{batch_size}_lr{lr}_rank{rank}_maxtoken{max_length}\""]},{"cell_type":"markdown","metadata":{"id":"5Y5TVTdBsbqY"},"source":["### Preparing training data"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":33,"status":"ok","timestamp":1698221973871,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"KJMaIhxuB5MQ"},"outputs":[],"source":["prompt_format = \"\"\"<s>[INST] <<SYS>>\n","You are a stock market analyst working for a brokerage firm. You are going to help me in analyzing the corporate announcement document submitted to the Indian stock exchange by a company.\n","If you are not able to analyze, please don't share false information.\n","<</SYS>\n","\n","Your task is to analyze the given context and generate a concise report as truthfully as possible by following the provided instructions.\n","### Instruction:\n","Extract important short points or keywords that can help me make a decision on whether to purchase or sell the stock of this company?\n","Based on your response can you also give me a one-liner sentiment(positive/neutral/negative) and a short and crisp conclusion on whether the stock price of the company will go upside or downside?\n","You have to follow the below format while generating the report.\n","```\n","### Key points: (mention the only key points here)\n","\n","### Sentiment: (mention the sentiment here)\n","\n","### Conclusion: (mention the final conclusion here)\n","```\n","\n","### Context:\n","{input}\n","\n","[/INST]\n","### Report:\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1698221973871,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"6jjEXYFz5nJg"},"outputs":[],"source":["# prompt_format = \"\"\"You are a stock market analyst working for a brokerage firm. You are going to help me in analyzing the corporate announcement document submitted to the Indian stock exchange by a company.\n","# If you are not able to analyze, please don't share false information.\n","\n","# Your task is to analyze the given context and generate a concise report as truthfully as possible by following the provided instructions.\n","# ### Instruction:\n","# Extract important short points or keywords that can help me make a decision on whether to purchase or sell the stock of this company?\n","# Based on your response can you also give me a one-liner sentiment(positive/neutral/negative) and a short and crisp conclusion on whether the stock price of the company will go upside or downside?\n","# You have to follow the below format while generating the report.\n","# ```\n","# ### Key points: (mention the only key points here)\n","\n","# ### Sentiment: (mention the sentiment here)\n","\n","# ### Conclusion: (mention the final conclusion here)\n","# ```\n","\n","# ### Context:\n","# {input}\n","\n","# ### Report:\"\"\""]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1698221973871,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"rZspaFapA1nF"},"outputs":[],"source":["IGNORE_INDEX = -100\n","\n","def _preprocess(\n","    sources: Sequence[str],\n","    targets: Sequence[str],\n","    tokenizer: PreTrainedTokenizer,\n","    max_length: int,\n",") -> Tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","    \"\"\"Preprocess the data by tokenizing.\"\"\"\n","    sequences = [s + t for s, t in zip(sources, targets)]\n","    sequences_token = tokenizer(\n","        sequences, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","    )\n","    sources_token = tokenizer(\n","        sources, max_length=max_length, padding=\"max_length\", truncation=True, return_tensors=\"pt\"\n","    )\n","\n","    assert sequences_token[\"attention_mask\"].dim() == 2, \"seq2seq model should be preprocessed differently\"\n","    labels = copy.deepcopy(sequences_token[\"input_ids\"])\n","    for i in range(labels.shape[0]):\n","        source_len = sources_token[\"attention_mask\"][i].sum().item()\n","        pad_len = max_length - sequences_token[\"attention_mask\"][i].sum().item()\n","        if tokenizer.padding_side == \"right\":\n","            # |prompt|completion|eos|pad|\n","            labels[i][:source_len] = IGNORE_INDEX\n","            if pad_len>0:\n","              labels[i][-pad_len:] = IGNORE_INDEX\n","        elif tokenizer.padding_side == \"left\":\n","            # |pad|prompt|completion|eos|\n","            labels[i][: pad_len + source_len] = IGNORE_INDEX\n","        else:\n","            raise RuntimeError()\n","\n","    return sequences_token[\"input_ids\"], labels, sequences_token[\"attention_mask\"]\n","\n","def SupervisedDataset(\n","  data: pd.DataFrame,\n","  tokenizer: PreTrainedTokenizer,\n","  max_length: int = 512,\n","):\n","  context_ls = list(data['pdf_extracted_data'])\n","  response_ls = list(data['chatgpt_prediction'])\n","\n","  sources = [\n","      prompt_format.format(input=context) for context in context_ls\n","  ]\n","  targets = [response + tokenizer.eos_token for response in response_ls]\n","\n","  input_ids, labels, attention_mask = _preprocess(sources, targets, tokenizer, max_length)\n","\n","  return dict(input_ids=input_ids, labels=labels, attention_mask=attention_mask)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1774,"status":"ok","timestamp":1698221975614,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"9zNua0eUszlm"},"outputs":[],"source":["train_df = pd.read_excel(\"/content/drive/MyDrive/Stocks/web_scraping/model_data/v1/train_data.xlsx\")\n","val_df = pd.read_excel(\"/content/drive/MyDrive/Stocks/web_scraping/model_data/v1/val_data.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":7519,"status":"ok","timestamp":1698221983129,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"YppMeSWmD4JR"},"outputs":[],"source":["tokenizer = AutoTokenizer.from_pretrained(MODEL_PATH, device_map='auto')\n","tokenizer.pad_token = tokenizer.eos_token\n","\n","train_dataset = SupervisedDataset(\n","  data=train_df,\n","  tokenizer=tokenizer,\n","  max_length=max_length,\n",")\n","train_dataset = pd.DataFrame({'input_ids': list(train_dataset['input_ids']), 'labels': list(train_dataset['labels']), 'attention_mask': list(train_dataset['attention_mask'])})\n","train_dataset['tmp'] = train_dataset['labels'].apply(lambda a: 1 if len([i for i in a if i != -100])==0 else 0)\n","train_dataset = train_dataset[train_dataset['tmp']==0].reset_index(drop=True)\n","train_dataset = train_dataset.drop(['tmp'], axis=1)\n","train_dataset = Dataset.from_dict(train_dataset)\n","\n","eval_dataset = SupervisedDataset(\n","  data=val_df,\n","  tokenizer=tokenizer,\n","  max_length=max_length,\n",")\n","eval_dataset = pd.DataFrame({'input_ids': list(eval_dataset['input_ids']), 'labels': list(eval_dataset['labels']), 'attention_mask': list(eval_dataset['attention_mask'])})\n","eval_dataset['tmp'] = eval_dataset['labels'].apply(lambda a: 1 if len([i for i in a if i != -100])==0 else 0)\n","eval_dataset = eval_dataset[eval_dataset['tmp']==0].reset_index(drop=True)\n","eval_dataset = eval_dataset.drop(['tmp'], axis=1)\n","eval_dataset = Dataset.from_dict(eval_dataset)"]},{"cell_type":"markdown","metadata":{"id":"b2DlJdLdH6Xo"},"source":["### Training"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":32,"status":"ok","timestamp":1698221983130,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"xQ3H3TYiIHG4"},"outputs":[],"source":["def load_peft_lora_model(model):\n","  peft_config = LoraConfig(\n","    task_type=TaskType.CAUSAL_LM,\n","    target_modules=['q_proj', 'v_proj'],\n","    bias='none',\n","    r=rank,\n","    lora_alpha=32,\n","    lora_dropout=0.01\n","  )\n","\n","  model = get_peft_model(model, peft_config)\n","  model.print_trainable_parameters()\n","  return model\n","\n","def load_model(pretrained_model_name_or_path: str) -> AutoModelForCausalLM:\n","  print(f\"Loading model for {pretrained_model_name_or_path}\")\n","  # model = AutoModelForCausalLM.from_pretrained(\n","  #   pretrained_model_name_or_path,\n","  #   device_map='auto'\n","  # )\n","\n","  # model = AutoModelForCausalLM.from_pretrained(\n","  #   pretrained_model_name_or_path,\n","  #   load_in_4bit=True,\n","  #   device_map='auto'\n","  # )\n","\n","  model = AutoModelForCausalLM.from_pretrained(\n","    pretrained_model_name_or_path,\n","    quantization_config=BitsAndBytesConfig(\n","      load_in_4bit=True,\n","      bnb_4bit_quant_type=\"nf4\",\n","      bnb_4bit_compute_dtype=torch.float16,\n","      bnb_4bit_use_double_quant=False\n","    ),\n","    device_map='auto'\n","  )\n","\n","  config = AutoConfig.from_pretrained(pretrained_model_name_or_path)\n","  model_hidden_size = config.hidden_size\n","\n","  model = prepare_model_for_kbit_training(model)\n","  model = load_peft_lora_model(model)\n","\n","  return model, model_hidden_size"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["50af6867a9bd4c1cae894208127bd8c1","d170fee505404ffdb5348fcbaf2d732c","84d1ec63aab5497eae4aa5a9e337bcd3","7d2aedffa204413ca597a60ef6343bbd","b7838a621b8c48a7ad5ea490528c3629","b10167993e3c4db58e931e96c107fabc","072d4eece58947e6a55afd243295288a","f468c9a28ae94730a577791cb2824b9d","62b23d04e8724a96a633a5230e5e1efe","9f61674390eb40a3a4ed695225869af0","2e7c22c84e4b4a6d94d9b76463137799"]},"executionInfo":{"elapsed":180047,"status":"ok","timestamp":1698222163145,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"rjV2hwvfxewS","outputId":"cb19a815-899a-46a6-c1a1-1a2e52eea0bd"},"outputs":[],"source":["model, model_hidden_size = load_model(MODEL_PATH)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":1022,"status":"ok","timestamp":1698222301355,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"sNcYuvKeH5Rj"},"outputs":[],"source":["def fine_tune_model(\n","  *,\n","  local_rank: str = None,\n","  local_output_dir: str = LOCAL_OUTPUT_DIR,\n","  dbfs_output_dir: str = None,\n","  epochs: int = num_epochs,\n","  per_device_train_batch_size: int = batch_size,\n","  per_device_eval_batch_size: int = batch_size,\n","  lr: float = lr,\n","  gradient_checkpointing: bool = False,\n","  gradient_accumulation_steps: int = 6,\n","  fp16: bool = False,\n","  bf16: bool = False,\n","  max_steps: int = 200,\n","  save_steps: int = 4,\n","  logging_steps: int = 4,\n","  eval_steps: int = 4,\n","  save_total_limit: int = 20,\n","  warmup_steps: int = 8\n","):\n","  os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:128\"\n","\n","  training_args = TrainingArguments(\n","    output_dir=local_output_dir,\n","    per_device_train_batch_size=per_device_train_batch_size,\n","    per_device_eval_batch_size=per_device_eval_batch_size,\n","    gradient_checkpointing=gradient_checkpointing,\n","    gradient_accumulation_steps=gradient_accumulation_steps,\n","    learning_rate=lr,\n","    num_train_epochs=epochs,\n","    weight_decay=1,\n","    do_eval=True,\n","    evaluation_strategy=\"steps\",\n","    eval_steps=eval_steps,\n","    fp16=fp16,\n","    bf16=bf16,\n","    logging_strategy=\"steps\",\n","    logging_steps=logging_steps,\n","    save_strategy=\"steps\",\n","    save_steps=save_steps,\n","    # max_steps=max_steps,\n","    save_total_limit=save_total_limit,\n","    local_rank=local_rank,\n","    warmup_steps=warmup_steps,\n","    report_to=[],\n","    logging_dir=local_output_dir,\n","    remove_unused_columns=False,\n","    label_names=[\"labels\"],\n","    ddp_find_unused_parameters=False\n","  )\n","\n","  trainer = Trainer(\n","    model=model,\n","    args=training_args,\n","    data_collator=data_collator,\n","    train_dataset=train_dataset,\n","    eval_dataset=eval_dataset\n","  )\n","\n","  print(\"Training the model\")\n","  train_results = trainer.train()\n","  trainer.log_metrics(\"train\", train_results.metrics)\n","  trainer.save_metrics(\"train\", train_results.metrics)\n","\n","  val_results = trainer.evaluate()\n","  print(val_results)\n","\n","  print(gpu_usage())\n","\n","  print(f\"Saving Model to {local_output_dir}\")\n","  trainer.save_model(output_dir=local_output_dir)\n","  tokenizer.save_pretrained(local_output_dir)\n","\n","  print(\"Training finished.\")"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":6,"status":"ok","timestamp":1698222302989,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"i0QORkrnCrFh","outputId":"2063d6d6-ed83-493a-dc03-bdcf77bbcaa7"},"outputs":[],"source":["gpu_usage()\n","torch.cuda.empty_cache()"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":593},"executionInfo":{"elapsed":12049548,"status":"ok","timestamp":1698234354190,"user":{"displayName":"Bhavesh Pancholi","userId":"03428474774076865127"},"user_tz":-330},"id":"bucyQ77zOhz1","outputId":"bbbe4bef-a803-423c-eee5-c168ba6b475e"},"outputs":[],"source":["fine_tune_model()"]},{"cell_type":"markdown","metadata":{"id":"QzkUxehd2Ao3"},"source":["### Test prediction"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def greedy_search_response(input_text):\n","  try:\n","    with torch.no_grad():\n","      inputs = tokenizer(input_text, return_tensors=\"pt\")\n","\n","      # Greedy Search\n","      outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"], do_sample=False, num_beams=1, max_new_tokens=400)\n","      return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0].split(\"Report:\")[1].strip()\n","  except Exception as e:\n","    print(f\"Error: {e}\")\n","    return \"\"\n","  \n","def top_p_sampling_response(input_text):\n","  try:\n","    with torch.no_grad():\n","      inputs = tokenizer(input_text, return_tensors=\"pt\")\n","\n","      # top-p sampling\n","      outputs = model.generate(input_ids=inputs[\"input_ids\"], attention_mask=inputs[\"attention_mask\"],\n","                               max_new_tokens=400,\n","                               do_sample=True,\n","                               top_p=0.75,\n","                               top_k=0,\n","                               temperature=0.2,\n","                               num_return_sequences = 1,\n","                               no_repeat_ngram_size=2)\n","      return tokenizer.batch_decode(outputs.detach().cpu().numpy(), skip_special_tokens=True)[0].split(\"Report:\")[1].strip()\n","  except Exception as e:\n","    print(f\"Error: {e}\")\n","    return \"\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"FfAXBjyz2CIK"},"outputs":[],"source":["test_df = pd.read_excel(\"/content/drive/MyDrive/Stocks/web_scraping/model_data/v1/test_data.xlsx\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NfVAx3rT2ES-"},"outputs":[],"source":["def func_to_extract_sentiment_label(text):\n","  sentiment_match = re.search(r'Sentiment:\\s*([A-Za-z]+)', text)\n","\n","  if sentiment_match:\n","      sentiment = sentiment_match.group(1)\n","  else:\n","      sentiment = \"Sentiment not found\"\n","\n","  return sentiment"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["model_summary = []\n","ct = 1\n","for i in list(test_df['pdf_extracted_data']):\n","  if ct%10 == 0:\n","    print(f\"Running iteration no {ct}\")\n","\n","  if pd.isnull(i) == True:\n","    model_summary.append(None)\n","  else:\n","    complete_prompt = prompt_format.format(input=i)\n","    res = greedy_search_response(complete_prompt)\n","    model_summary.append(res)\n","\n","  if ct%20 == 0:\n","    tmp_data = test_df.iloc[:ct].copy()\n","    tmp_data['model_summary'] = model_summary\n","    tmp_data['sentiment'] = tmp_data['model_summary'].apply(lambda a: func_to_extract_sentiment_label(a))\n","    tmp_data.to_excel(f\"/content/drive/MyDrive/Stocks/finetune_models/Llama-2-7b-chat-hf/ep1.5_bs2_lr0.001_rank8_maxtoken2000/checkpoints/greedy_test_prediction_after_{ct}.xlsx\", index=False)\n","\n","  ct = ct + 1\n","\n","test_df['model_summary'] = model_summary\n","test_df['sentiment'] = test_df['model_summary'].apply(lambda a: func_to_extract_sentiment_label(a))"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["test_df.to_excel(\"/content/drive/MyDrive/Stocks/finetune_models/Llama-2-7b-chat-hf/ep1.5_bs2_lr0.001_rank8_maxtoken2000/greedy_test_prediction.xlsx\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def get_sentence_similarity(reference = '', generated = '',  model_name = None):\n","  '''\n","  Generate cosine similarity score based on embeddings of two strings\n","  Parameters:\n","    reference (str) : Reference string to check similarity\n","    generated (str) : Generated/Target string to check similarity\n","    model_name (str) : Sentence tranformer model names\n","  Returns:\n","    Similarity score (float) : Cosine similarity score based on embeddings of the two strings\n","  '''\n","  if model_name == None:\n","    model = SentenceTransformer('all-minilm-l6-v2')\n","  else:\n","    model = SentenceTransformer(model_name)\n","\n","  # convert to embeddings\n","  embedding1 = model.encode(reference, convert_to_tensor=True)\n","  embedding2 = model.encode(generated, convert_to_tensor=True)\n","\n","  # compute similarity scores of two embeddings\n","  cosine_scores = util.pytorch_cos_sim(embedding1, embedding2)\n","\n","  return cosine_scores.item()\n","\n","def get_bleu_score(reference, candidate):\n","  '''\n","  Function to get BLEU scores for two strings\n","  '''\n","  candidate_ = candidate.split()\n","  reference_ = []\n","  reference_.append(reference.split())\n","  return sentence_bleu(reference_, candidate_, weights=(1, 0, 0, 0))\n","\n","def get_evaluation_metrics(actuals, predicted):\n","  '''\n","  Generate benchamrking scores on different metrics for generated text\n","\n","  Parameters:\n","    actuals (str | list) : Actual text or reference\n","    predicted (str | list) : Generated text or predictions\n","  Returns:\n","    blue_score (float) : Mean BLUE score\n","    rouge1 (float): Mean ROUGE1 score\n","    rougeL (float): Mean ROUGEL score\n","    sentence similarity (float): Mean Cosine Similariy score on embeddedings\n","  '''\n","  if isinstance(actuals, list) and isinstance(predicted, list):\n","    df = pd.DataFrame({'actuals':actuals,'predicted':predicted})\n","  elif isinstance(actuals, str) and isinstance(predicted, str):\n","    df = pd.DataFrame({'actuals':[actuals],'predicted':[predicted]})\n","\n","  scorer = rouge_scorer.RougeScorer(['rouge1', 'rougeL'], use_stemmer=True)\n","\n","  df['blue_score'] = df.apply(lambda x: get_bleu_score(x['actuals'], x['predicted']), axis = 1)\n","  df['rougue1'] = df.apply(lambda x: scorer.score(x['actuals'], x['predicted'])['rouge1'].fmeasure, axis = 1)\n","  df['rougeL'] = df.apply(lambda x: scorer.score(x['actuals'], x['predicted'])['rougeL'].fmeasure, axis = 1)\n","  df['sentence_similarity'] = df.apply(lambda x: get_sentence_similarity(reference = x['actuals'], generated = x['predicted']), axis = 1)\n","\n","  return df['blue_score'].mean(), df['rougue1'].mean(), df['rougeL'].mean(), df['sentence_similarity'].mean(),df"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["bleu,rouge_one,rouge_l,semantic,scores_df  =  get_evaluation_metrics(test_df['chatgpt_prediction'].tolist(), test_df['model_summary'].tolist())\n","scores_df['COMPANY NAME'] = test_df['COMPANY NAME']\n","scores_df['ATTACHMENT'] = test_df['ATTACHMENT']\n","scores_df['pdf_extracted_data'] = test_df['pdf_extracted_data']\n","scores_df = scores_df[['COMPANY NAME','ATTACHMENT','pdf_extracted_data','actuals','predicted','blue_score','rougue1','rougeL','sentence_similarity']]\n","print(bleu,rouge_one,rouge_l,semantic)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["scores_df.to_excel(\"/content/drive/MyDrive/Stocks/finetune_models/Llama-2-7b-chat-hf/ep1.5_bs2_lr0.001_rank8_maxtoken2000/greedy_test_prediction_scores.xlsx\", index=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.9"},"widgets":{"application/vnd.jupyter.widget-state+json":{"072d4eece58947e6a55afd243295288a":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"2e7c22c84e4b4a6d94d9b76463137799":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"DescriptionStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"DescriptionStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","description_width":""}},"50af6867a9bd4c1cae894208127bd8c1":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HBoxModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HBoxModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HBoxView","box_style":"","children":["IPY_MODEL_d170fee505404ffdb5348fcbaf2d732c","IPY_MODEL_84d1ec63aab5497eae4aa5a9e337bcd3","IPY_MODEL_7d2aedffa204413ca597a60ef6343bbd"],"layout":"IPY_MODEL_b7838a621b8c48a7ad5ea490528c3629"}},"62b23d04e8724a96a633a5230e5e1efe":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"ProgressStyleModel","state":{"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"ProgressStyleModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"StyleView","bar_color":null,"description_width":""}},"7d2aedffa204413ca597a60ef6343bbd":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_9f61674390eb40a3a4ed695225869af0","placeholder":"​","style":"IPY_MODEL_2e7c22c84e4b4a6d94d9b76463137799","value":" 2/2 [02:49&lt;00:00, 73.38s/it]"}},"84d1ec63aab5497eae4aa5a9e337bcd3":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"FloatProgressModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"FloatProgressModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"ProgressView","bar_style":"success","description":"","description_tooltip":null,"layout":"IPY_MODEL_f468c9a28ae94730a577791cb2824b9d","max":2,"min":0,"orientation":"horizontal","style":"IPY_MODEL_62b23d04e8724a96a633a5230e5e1efe","value":2}},"9f61674390eb40a3a4ed695225869af0":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b10167993e3c4db58e931e96c107fabc":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"b7838a621b8c48a7ad5ea490528c3629":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}},"d170fee505404ffdb5348fcbaf2d732c":{"model_module":"@jupyter-widgets/controls","model_module_version":"1.5.0","model_name":"HTMLModel","state":{"_dom_classes":[],"_model_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_model_name":"HTMLModel","_view_count":null,"_view_module":"@jupyter-widgets/controls","_view_module_version":"1.5.0","_view_name":"HTMLView","description":"","description_tooltip":null,"layout":"IPY_MODEL_b10167993e3c4db58e931e96c107fabc","placeholder":"​","style":"IPY_MODEL_072d4eece58947e6a55afd243295288a","value":"Loading checkpoint shards: 100%"}},"f468c9a28ae94730a577791cb2824b9d":{"model_module":"@jupyter-widgets/base","model_module_version":"1.2.0","model_name":"LayoutModel","state":{"_model_module":"@jupyter-widgets/base","_model_module_version":"1.2.0","_model_name":"LayoutModel","_view_count":null,"_view_module":"@jupyter-widgets/base","_view_module_version":"1.2.0","_view_name":"LayoutView","align_content":null,"align_items":null,"align_self":null,"border":null,"bottom":null,"display":null,"flex":null,"flex_flow":null,"grid_area":null,"grid_auto_columns":null,"grid_auto_flow":null,"grid_auto_rows":null,"grid_column":null,"grid_gap":null,"grid_row":null,"grid_template_areas":null,"grid_template_columns":null,"grid_template_rows":null,"height":null,"justify_content":null,"justify_items":null,"left":null,"margin":null,"max_height":null,"max_width":null,"min_height":null,"min_width":null,"object_fit":null,"object_position":null,"order":null,"overflow":null,"overflow_x":null,"overflow_y":null,"padding":null,"right":null,"top":null,"visibility":null,"width":null}}}}},"nbformat":4,"nbformat_minor":0}
